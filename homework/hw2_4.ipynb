{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from glob import glob\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "#from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from skimage.color import rgb2gray\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model, load_model, save_model\n",
    "from tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPath = \"../data/kaggle_3m/\"\n",
    "\n",
    "dirs = []\n",
    "images = []\n",
    "masks = []\n",
    "for dirname, _, filenames in os.walk(DataPath):\n",
    "    for filename in filenames:\n",
    "        if 'mask'in filename:\n",
    "            dirs.append(dirname.replace(DataPath, ''))\n",
    "            masks.append(filename)\n",
    "            images.append(filename.replace('_mask', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TCGA_CS_4941_19960909_10_mask.tif', 'TCGA_CS_4941_19960909_11_mask.tif', 'TCGA_CS_4941_19960909_12_mask.tif', 'TCGA_CS_4941_19960909_13_mask.tif', 'TCGA_CS_4941_19960909_14_mask.tif', 'TCGA_CS_4941_19960909_15_mask.tif', 'TCGA_CS_4941_19960909_16_mask.tif', 'TCGA_CS_4941_19960909_17_mask.tif', 'TCGA_CS_4941_19960909_18_mask.tif', 'TCGA_CS_4941_19960909_19_mask.tif'] ['TCGA_CS_4941_19960909_10.tif', 'TCGA_CS_4941_19960909_11.tif', 'TCGA_CS_4941_19960909_12.tif', 'TCGA_CS_4941_19960909_13.tif', 'TCGA_CS_4941_19960909_14.tif', 'TCGA_CS_4941_19960909_15.tif', 'TCGA_CS_4941_19960909_16.tif', 'TCGA_CS_4941_19960909_17.tif', 'TCGA_CS_4941_19960909_18.tif', 'TCGA_CS_4941_19960909_19.tif']\n"
     ]
    }
   ],
   "source": [
    "print(masks[:10], images[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3929, 3929, 3929)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dirs), len(images), len(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath_df = pd.DataFrame({'directory':dirs, 'images': images, 'masks': masks})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directory</th>\n",
       "      <th>images</th>\n",
       "      <th>masks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA_CS_4941_19960909</td>\n",
       "      <td>TCGA_CS_4941_19960909_10.tif</td>\n",
       "      <td>TCGA_CS_4941_19960909_10_mask.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA_CS_4941_19960909</td>\n",
       "      <td>TCGA_CS_4941_19960909_11.tif</td>\n",
       "      <td>TCGA_CS_4941_19960909_11_mask.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA_CS_4941_19960909</td>\n",
       "      <td>TCGA_CS_4941_19960909_12.tif</td>\n",
       "      <td>TCGA_CS_4941_19960909_12_mask.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA_CS_4941_19960909</td>\n",
       "      <td>TCGA_CS_4941_19960909_13.tif</td>\n",
       "      <td>TCGA_CS_4941_19960909_13_mask.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA_CS_4941_19960909</td>\n",
       "      <td>TCGA_CS_4941_19960909_14.tif</td>\n",
       "      <td>TCGA_CS_4941_19960909_14_mask.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               directory                        images  \\\n",
       "0  TCGA_CS_4941_19960909  TCGA_CS_4941_19960909_10.tif   \n",
       "1  TCGA_CS_4941_19960909  TCGA_CS_4941_19960909_11.tif   \n",
       "2  TCGA_CS_4941_19960909  TCGA_CS_4941_19960909_12.tif   \n",
       "3  TCGA_CS_4941_19960909  TCGA_CS_4941_19960909_13.tif   \n",
       "4  TCGA_CS_4941_19960909  TCGA_CS_4941_19960909_14.tif   \n",
       "\n",
       "                               masks  \n",
       "0  TCGA_CS_4941_19960909_10_mask.tif  \n",
       "1  TCGA_CS_4941_19960909_11_mask.tif  \n",
       "2  TCGA_CS_4941_19960909_12_mask.tif  \n",
       "3  TCGA_CS_4941_19960909_13_mask.tif  \n",
       "4  TCGA_CS_4941_19960909_14_mask.tif  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagePath_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath_df['image-path'] = DataPath + imagePath_df['directory'] + '/' + imagePath_df['images']\n",
    "imagePath_df['mask-path'] = DataPath + imagePath_df['directory'] + '/' + imagePath_df['masks'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3437, 5) \n",
      "Val: (786, 5) \n",
      "Test: (492, 5)\n"
     ]
    }
   ],
   "source": [
    "# split data into 70% train, 20% validation, and 10% test\n",
    "train, val = train_test_split(imagePath_df, test_size=0.2, random_state=42)\n",
    "train, test = train_test_split(imagePath_df, test_size=0.125, random_state=42)\n",
    "print(f\"Train: {train.shape} \\nVal: {val.shape} \\nTest: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "ImgHieght = 256\n",
    "ImgWidth = 256\n",
    "Channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = dict(rotation_range=0.2,\n",
    "                        width_shift_range=0.05,\n",
    "                        height_shift_range=0.05,\n",
    "                        shear_range=0.05,\n",
    "                        zoom_range=0.05,\n",
    "                        horizontal_flip=True,\n",
    "                        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3437 validated image filenames.\n",
      "Found 3437 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# image generator\n",
    "imagegen = ImageDataGenerator(rescale=1./255., **data_augmentation)\n",
    "maskgen = ImageDataGenerator(rescale=1./255., **data_augmentation)\n",
    "\n",
    "# train generator\n",
    "timage_generator=imagegen.flow_from_dataframe(dataframe=train,\n",
    "                                            x_col=\"image-path\",\n",
    "                                            batch_size= BATCH_SIZE,\n",
    "                                            seed=42,\n",
    "                                            class_mode=None,\n",
    "                                            target_size=(ImgHieght,ImgWidth),\n",
    "                                            color_mode='rgb')\n",
    "# validation data generator\n",
    "tmask_generator=maskgen.flow_from_dataframe(dataframe=train,\n",
    "                                            x_col=\"mask-path\",\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            seed=42,\n",
    "                                            class_mode=None,\n",
    "                                            target_size=(ImgHieght,ImgWidth),\n",
    "                                            color_mode='grayscale')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 786 validated image filenames.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 786 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# image generator\n",
    "imagegen = ImageDataGenerator(rescale=1./255.)\n",
    "maskgen = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "# define validation or test\n",
    "DATA_FRAME = val\n",
    "# DATA_FRAME = test\n",
    "\n",
    "# image generator for image/mask\n",
    "vimage_generator=imagegen.flow_from_dataframe(dataframe=DATA_FRAME,\n",
    "                                            x_col=\"image-path\",\n",
    "                                            batch_size= BATCH_SIZE,\n",
    "                                            seed=42,\n",
    "                                            class_mode=None,\n",
    "                                            target_size=(ImgHieght,ImgWidth),\n",
    "                                            color_mode='rgb')\n",
    "\n",
    "vmask_generator=maskgen.flow_from_dataframe(dataframe=DATA_FRAME,\n",
    "                                            x_col=\"mask-path\",\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            seed=42,\n",
    "                                            class_mode=None,\n",
    "                                            target_size=(ImgHieght,ImgWidth),\n",
    "                                            color_mode='grayscale')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iterator(image_gen, mask_gen):\n",
    "    for img, mask in zip(image_gen, mask_gen):\n",
    "        yield img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = data_iterator(timage_generator, tmask_generator)\n",
    "valid_gen = data_iterator(vimage_generator, vmask_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n",
    "    \"\"\"Function to define the UNET Model\"\"\"\n",
    "    # Contracting Path\n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "    \n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "    \n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "    \n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input((ImgHieght, ImgWidth, 3), name='img')\n",
    "model = get_unet(input_img, n_filters=16, dropout=0.2, batchnorm=True).to(device)\n",
    "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " img (InputLayer)            [(None, 256, 256, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 256, 256, 16)         448       ['img[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 256, 256, 16)         64        ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 256, 256, 16)         0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 128, 128, 16)         0         ['activation_1[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 128, 128, 16)         0         ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 128, 128, 32)         4640      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 128, 128, 32)         128       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 128, 128, 32)         0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 32)           0         ['activation_3[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 64, 64, 32)           0         ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 64, 64, 64)           18496     ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 64, 64, 64)           256       ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 64, 64, 64)           0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 64)           0         ['activation_5[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 32, 32, 64)           0         ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 32, 32, 128)          73856     ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 32, 32, 128)          512       ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 32, 32, 128)          0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 128)          0         ['activation_7[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 16, 16, 128)          0         ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 16, 16, 256)          295168    ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 16, 16, 256)          1024      ['conv2d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, 16, 16, 256)          0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 32, 32, 128)          295040    ['activation_9[0][0]']        \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 32, 32, 256)          0         ['conv2d_transpose[0][0]',    \n",
      "                                                                     'activation_7[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 32, 32, 256)          0         ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 32, 32, 128)          295040    ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 32, 32, 128)          512       ['conv2d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, 32, 32, 128)          0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 64, 64, 64)           73792     ['activation_11[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 64, 64, 128)          0         ['conv2d_transpose_1[0][0]',  \n",
      " )                                                                   'activation_5[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 64, 64, 128)          0         ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 64, 64, 64)           73792     ['dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 64, 64, 64)           256       ['conv2d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, 64, 64, 64)           0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 128, 128, 32)         18464     ['activation_13[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 128, 128, 64)         0         ['conv2d_transpose_2[0][0]',  \n",
      " )                                                                   'activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 128, 128, 64)         0         ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 128, 128, 32)         18464     ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 128, 128, 32)         128       ['conv2d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_15 (Activation)  (None, 128, 128, 32)         0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2D  (None, 256, 256, 16)         4624      ['activation_15[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 256, 256, 32)         0         ['conv2d_transpose_3[0][0]',  \n",
      " )                                                                   'activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 256, 256, 32)         0         ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 256, 256, 16)         4624      ['dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 256, 256, 16)         64        ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_17 (Activation)  (None, 256, 256, 16)         0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 256, 256, 1)          17        ['activation_17[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1179409 (4.50 MB)\n",
      "Trainable params: 1177937 (4.49 MB)\n",
      "Non-trainable params: 1472 (5.75 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=10, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=1e-5, verbose=1),\n",
    "    ModelCheckpoint('model-brain-mri.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]\n",
    "STEP_SIZE_TRAIN = timage_generator.n/BATCH_SIZE\n",
    "STEP_SIZE_VALID = vimage_generator.n/BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yuzho\\Documents\\psyc221_ML_neuroimaging\\homework\\hw2_4.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/yuzho/Documents/psyc221_ML_neuroimaging/homework/hw2_4.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_gen,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuzho/Documents/psyc221_ML_neuroimaging/homework/hw2_4.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                     steps_per_epoch\u001b[39m=\u001b[39;49mSTEP_SIZE_TRAIN,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuzho/Documents/psyc221_ML_neuroimaging/homework/hw2_4.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuzho/Documents/psyc221_ML_neuroimaging/homework/hw2_4.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuzho/Documents/psyc221_ML_neuroimaging/homework/hw2_4.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuzho/Documents/psyc221_ML_neuroimaging/homework/hw2_4.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mvalid_gen,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuzho/Documents/psyc221_ML_neuroimaging/homework/hw2_4.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                    validation_steps\u001b[39m=\u001b[39;49mSTEP_SIZE_VALID)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = model.fit(train_gen,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_gen,\n",
    "                   validation_steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yuzho\\Documents\\psyc221_ML_neuroimaging\\homework\\hw2_4.ipynb Cell 31\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuzho/Documents/psyc221_ML_neuroimaging/homework/hw2_4.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuzho/Documents/psyc221_ML_neuroimaging/homework/hw2_4.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m\"\u001b[39m\u001b[39mLearning curve\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/yuzho/Documents/psyc221_ML_neuroimaging/homework/hw2_4.ipynb#X46sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(results\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m, color\u001b[39m=\u001b[39msns\u001b[39m.\u001b[39mxkcd_rgb[\u001b[39m'\u001b[39m\u001b[39mgreenish teal\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuzho/Documents/psyc221_ML_neuroimaging/homework/hw2_4.ipynb#X46sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(results\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m, color\u001b[39m=\u001b[39msns\u001b[39m.\u001b[39mxkcd_rgb[\u001b[39m'\u001b[39m\u001b[39mamber\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuzho/Documents/psyc221_ML_neuroimaging/homework/hw2_4.ipynb#X46sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mplot( np\u001b[39m.\u001b[39margmin(results\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m]), np\u001b[39m.\u001b[39mmin(results\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m]), marker\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m, color\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbest model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqoAAAKrCAYAAAA52a/PAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwxUlEQVR4nO3df5TVdZ348dedZkbRGkZ+BYIMID/MFn9EaQtUIKUiVCDoIrZqFEm1aadN1+iQtsFZ0bZgRQ4VrUoKwqEF5MdBEXBLpLIsFUkBgU0FhAkuHJIfM8z9/uFhvjvO4HJHYN5wH49z+ON+5vO59315DePTz/3cuZlcLpcLAABITFFTLwAAABoiVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEaoVOnTtGpU6emXgbAKU2oAsdFJpOJTCbT1MsA4CRW3NQLADgZLV++vKmXAHDKy+RyuVxTLwI49Rw+m+pHDACN5aV/IAmzZs2K/v37R3l5eZx++unxoQ99KMaPHx8HDhyot+/8+fPjC1/4QnTv3j3OPPPMOPPMM6NXr17xH//xH1FTU1Nv/5tuuikymUxs3Lgx7rvvvrjggguiWbNm0a9fvzpf37x5c/zkJz+Jnj17xumnnx4f/OAH4ytf+Urs3r273n02dI3qgw8+GJlMJh588MFYuXJl9OvXLz7wgQ9EWVlZDBo0KP785z83+NzXrVsXw4YNi7POOivOPPPM6N27dyxevLjO/R2tQ4cOxbRp06JPnz7RvHnzaNasWXTt2jW+/OUvx/r16+v9nWzevLnefTz11FORyWTirrvuqrO9X79+kclk4uDBg/Gv//qv0aNHjzjttNPipptuirvvvjsymUxMnjy5wXVt2bIliouL46Mf/Wid7dXV1TF16tT4+Mc/HmVlZXHGGWfExRdfHFOmTGlwlkBh8dI/0ORGjRoVDzzwQHTo0CGGDRsW5eXl8Zvf/CbGjRsXy5cvj2XLlkVx8f//cXXHHXdEUVFRXHrppdG+ffvYvXt3rFixIm699dZ49tln4xe/+EWDj3PrrbfGr3/96xg0aFBcddVV8b73va/O12+//fZ4/PHH47Of/WxcfvnlsXLlyvjZz34WGzZsiBUrVhz181m0aFEsWLAgBg4cGGPGjIm1a9fGkiVL4tlnn421a9dGq1atavd9+eWXo3fv3rFr164YNGhQXHDBBbFx48YYOnRoXHXVVXn9PR48eDAGDx4cy5Yti3POOSdGjhwZZWVlsXnz5pg3b1707ds3unXrltd9NmTYsGHx7LPPxsCBA2PIkCHRpk2bGDFiRHz3u9+NGTNmxK233lrvmIcffjgOHToUN910U+22qqqq+OxnPxuPP/549OjRI0aOHBmnn356rFy5Mr7xjW/Eb3/72yPOEigQOYDjICJyR/Mj5oEHHshFRG7o0KG5t956q87X7rzzzlxE5CZNmlRn+4YNG+rdz6FDh3I33HBDLiJyv/nNb+p87cYbb8xFRO7ss8/Obdy4sd6xh79+zjnn5P7nf/6ndntVVVXuE5/4RC4icr/97W/rHFNRUZGrqKho8Lm8733vyz355JN1vnbHHXfkIiI3ceLEOtsvu+yyXETkpk6dWmf7kiVLav8OH3jggXprbsh3vvOdXETkPvvZz+b2799f52v79+/Pbd++vd5z3rRpU737WblyZS4icnfeeWed7Z/61KdyEZHr2bNnbseOHfWOu/zyy3MRkXvxxRfrfe3888/PlZaW5iorK2u3HZ7vP/3TP+Wqq6trt1dXV+dGjRqVi4jc/Pnzj+q5A6cmL/0DTWry5MlRXFwc//mf/xnNmjWr87Vx48ZFy5Yt45FHHqmz/dxzz613P0VFRbVn8h5//PEGH+v222+Pzp07H3Et3/ve96Jjx461t4uLi+OLX/xiRET87ne/O7onFBEjRoyIAQMG1Nn2la98pd79vPbaa7FixYro2rVr3HzzzXX2HzhwYHz6058+6sc8dOhQTJ06NZo1axbTpk2L0047rc7XTzvttGjduvVR39+7+cEPflDnrPBhN954Y0REPPTQQ3W2//73v4+1a9fGoEGDomXLlhERUVNTE/fdd1+0bds2fvzjH9c5u/2+970v/v3f/z0ymUy92QOFxUv/QJN566234vnnn49WrVrFpEmTGtzntNNOq3dt51//+te49957Y8mSJbFx48b429/+Vufrb7zxRoP3dckll7zret55/WRExDnnnBMREbt27XrXYxtzP3/6058iIuLv//7vo6io/nmDvn37xpNPPnlUj/nyyy/H7t2749JLL42zzz77qNfaGEf6exw6dGg0b948Hnnkkbj77rtr4/NwuP7vl/3XrVsXO3fujG7dusX48eMbvL9mzZod8bpeoDAIVaDJ7Nq1K3K5XOzYsSO+//3vH9Ux2Ww2Pvaxj8WmTZvikksuiRtuuCFatGgRxcXFkc1mY/LkyQ2+ASsiom3btu963+Xl5fW2Hb429tChQ0e1vnzu5/CbtD74wQ82eD9H2t6QbDYbERHt27c/6mMa60h/j82aNYtrr702fvazn8UTTzwRAwcOjIMHD8asWbOidevWMXDgwNp9//rXv0ZExPr169919nv37j22iwdOKl76B5pM8+bNIyLi4osvjlwu965/Dps+fXps2rQp7rzzzvjtb38bU6dOjfHjx8ddd90V//AP//Cuj5faBxCUlZVFRMSbb77Z4NePtL0hh+P4SGeT3+nwGdzq6up6XzscvUfybn+P73z5f/HixfHXv/41Ro4cGSUlJbX7HZ790KFD33XumzZtOqrnA5yahCrQZN7//vfHhz/84XjppZdi586dR3XMhg0bIuLtd56/03//938f0/UdbxdddFFERKxevbrBX8X09NNPH/V9nXfeeVFeXh4vvPBCbNmy5f/c/6yzzoqIt6+Tfaff//73R/2479SnT5/o1q1bLFiwIHbv3l0brIcD9p3r/c1vfhNVVVWNfjzg1CZUgSb1rW99Kw4ePBijRo1q8Ezerl274rnnnqu9ffh3lz711FN19vvjH/8Y//Zv/3YcV3rsdezYMfr16xcbNmyIn/zkJ3W+tnTp0qO+PjXi7Tcgfe1rX4t9+/bFmDFj6l3+cPDgwdixY0ft7cPXmf7sZz+rs9+LL754xN+FerRuvPHG2L9/f0ydOjWWLFkSF1xwQVx88cV19ikuLo5vfOMbsXXr1rjlllti37599e5n69atsXbt2ve0FuDk5hpV4Lj632+geaepU6fGqFGj4g9/+ENMnTo1zj333LjiiiuiY8eOsXPnzti0aVP86le/ii9+8Ysxbdq0iIi44YYb4t57741vfvObsXLlyujWrVusX78+Fi1aFFdffXXMnj37BD2zY+P++++PPn36xNe+9rXaqNu4cWP88pe/jM9//vOxYMGCBt9o1ZDDl0MsXLgwunfvHoMHD44PfOAD8dprr8UTTzwR9957b+08Pv/5z0e3bt1i1qxZ8frrr8ell14af/nLX2LBggXx+c9/PubMmdPo5/SP//iP8b3vfS/uvPPOqKqqqnc29bBx48bF888/H9OmTYuFCxfGZZddFu3bt4/t27fH+vXrY9WqVTFhwoQ4//zzG70W4OQmVIHj6p2/quh/mzRpUpxxxhlx//33x8CBA2PatGnx5JNPRjabjRYtWkTHjh3jtttuiy984Qu1x5x99tnx61//Ou644454+umn4/HHH4/zzjsvpk6dGp/+9KdPulA9//zzY/Xq1TF27NhYsWJFrFixIi644IKYN29e/PnPf44FCxbUXsv6fyktLY2lS5fGtGnTYsaMGfHQQw9FLpeLs88+O4YOHRp9+/at3ff000+P5cuXx7e//e1YtmxZPPvss/F3f/d3MXPmzGjRosV7CtWOHTtG//79Y/ny5VFcXBzXX399g/uVlJTE/Pnz4+GHH44HH3wwFi1aFHv37o3WrVtH586d4wc/+MERjwUKQyaX80HcACm6/vrrY+bMmfHyyy9Hjx49mno5ACeca1QBmlBNTU1s27at3vbly5fH7Nmz4/zzzxepQMHy0j9AEzp48GCcc8450b9//zjvvPOiuLg4XnrppVi2bFmUlpbG/fff39RLBGgyXvoHaEKHDh2Kb37zm7FixYp4/fXX46233opWrVrFJz/5ybjjjjvqvVseoJDkHapr166Nxx57LDZt2hS7du2Kb3/72//nxxK+9NJLMWPGjHjttdeiZcuWMWzYsOjXr997WTcAAKe4vK9RPXDgQHTq1Cm+9KUvHdX+27dvj7vvvjs+/OEPxz333BODBg2KadOm1X7GNQAANCTva1QvvvjivF6KeuKJJ6JNmzZxww03REREhw4d4uWXX47FixfXfioLAAC803F/1//69eujZ8+edbZdeOGFsW7duiMeU1VVFW+99VadPz5iDwCgsBz3d/1ns9lo3rx5nW3NmzePffv2xcGDB6O0tLTeMfPmzYu5c+fW3u7Tp0/ceuutx3upAAAkJMlfTzV06NAYPHhw7e1MJhMRb3/md3V1dVMtixMkk8lEq1atorKyMvxSilOfeRcW8y4s5l1YiouL46yzzjq293lM760B5eXlsXv37jrbdu/eHc2aNWvwbGrE2x+rV1JSUm97dXW1SwAKwOH/MamqqvKDrQCYd2Ex78Ji3rxXx/0a1W7dusWLL75YZ9sLL7wQ3bt3P94PDQDASSzvUN2/f39s3rw5Nm/eHBFv//qpzZs3R2VlZUREzJw5M6ZMmVK7/+WXXx7bt2+Phx9+ON544414/PHHY/Xq1TFo0KBj8wwAADgl5f3S/6uvvhrf//73a2/PmDEjIiI+9alPxde//vXYtWtXbbRGRLRp0ybuuOOOeOihh2LJkiXRsmXLGDNmjF9NBQDAuzqpPkJ1x44drlEtAJlMJtq1axdbt251TVMBMO/CYt6FxbwLS0lJSbRu3fqY3udxv0YVAAAaQ6gCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASRKqAAAkSagCAJAkoQoAQJKEKgAASSpuzEFLly6NhQsXRjabjYqKihg1alR07dr1iPsvXrw4nnjiiaisrIyysrK49NJLY+TIkVFaWtrohQMAcGrL+4zqM888EzNmzIjhw4fHxIkTo6KiIiZMmBC7d+9ucP+nn346Zs6cGddcc038+Mc/jjFjxsTq1atj1qxZ73nxAACcuvIO1UWLFsWAAQOif//+0aFDhxg9enSUlpbGypUrG9z/lVdeiR49ekTfvn2jTZs2ceGFF0afPn1iw4YN73nxAACcuvJ66b+6ujo2btwYQ4YMqd1WVFQUPXv2jHXr1jV4TI8ePeLXv/51bNiwIbp27Rpvvvlm/PGPf4xPfOITR3ycqqqqqKqqqr2dyWSiWbNmkclkIpPJ5LNkTkKHZ2zWhcG8C4t5FxbzLizHY855heqePXuipqYmysvL62wvLy+PLVu2NHhM3759Y8+ePTFu3LiIiDh06FB85jOfiauvvvqIjzNv3ryYO3du7e3OnTvHxIkTo1WrVvksl5Nc27Ztm3oJnEDmXVjMu7CYN43VqDdT5eOll16KefPmxZe//OXo1q1bbNu2LR544IGYO3duDB8+vMFjhg4dGoMHD669fbjQKysr65xp5dSUyWSibdu2sW3btsjlck29HI4z8y4s5l1YzLuwlJSUHPOTinmFallZWRQVFUU2m62zPZvN1jvLetjs2bPjk5/8ZAwYMCAiIjp27Bj79++Pn/70p3H11VdHUVH9y2RLSkqipKSk3vZcLucbvYCYd2Ex78Ji3oXFvAvD8ZhxXm+mKi4uji5dusSaNWtqt9XU1MSaNWuie/fuDR5z4MCBetcsNBSnAADwv+X90v/gwYPj/vvvjy5dukTXrl1jyZIlceDAgejXr19EREyZMiVatGgRI0eOjIiIXr16xeLFi6Nz5861L/3Pnj07evXqJVgBADiivEO1d+/esWfPnpgzZ05ks9no1KlTjB07tval/8rKyjpnUIcNGxaZTCYeffTR2LlzZ5SVlUWvXr3iuuuuO2ZPAgCAU08mdxJdNLJjxw5vpioAmUwm2rVrF1u3bnVNUwEw78Ji3oXFvAtLSUlJtG7d+pjep9feAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAkiRUAQBIklAFACBJQhUAgCQJVQAAklTcmIOWLl0aCxcujGw2GxUVFTFq1Kjo2rXrEff/29/+FrNmzYrf/e53sXfv3mjdunXceOON8ZGPfKTRCwcA4NSWd6g+88wzMWPGjBg9enR069YtFi9eHBMmTIhJkyZF8+bN6+1fXV0d48ePj7KysvjWt74VLVq0iMrKyjjjjDOOyRMAAODUlHeoLlq0KAYMGBD9+/ePiIjRo0fHc889FytXrowhQ4bU23/FihWxd+/e+MEPfhDFxW8/XJs2bd7bqgEAOOXlFarV1dWxcePGOkFaVFQUPXv2jHXr1jV4zB/+8Ifo1q1b/PznP4/f//73UVZWFn369IkhQ4ZEUZFLZAEAaFheobpnz56oqamJ8vLyOtvLy8tjy5YtDR7z5ptvxo4dO6Jv377xne98J7Zt2xbTp0+PQ4cOxTXXXNPgMVVVVVFVVVV7O5PJRLNmzSKTyUQmk8lnyZyEDs/YrAuDeRcW8y4s5l1YjsecG/VmqnzkcrkoKyuLm2++OYqKiqJLly6xc+fOeOyxx44YqvPmzYu5c+fW3u7cuXNMnDgxWrVqdbyXS0Latm3b1EvgBDLvwmLehcW8aay8QrWsrCyKiooim83W2Z7NZuudZT2svLw8iouL67zM3759+8hms1FdXV173er/NnTo0Bg8eHDt7cOFXllZWedMK6emTCYTbdu2jW3btkUul2vq5XCcmXdhMe/CYt6FpaSk5JifVMwrVIuLi6NLly6xZs2auOSSSyIioqamJtasWRNXXnllg8f06NEjVq1aFTU1NbWxunXr1jjrrLMajNSIt59oSUlJve25XM43egEx78Ji3oXFvAuLeReG4zHjvN/NNHjw4Fi+fHk89dRT8frrr8f06dPjwIED0a9fv4iImDJlSsycObN2/8svvzz27t0bDz74YGzZsiWee+65mDdvXlxxxRXH7EkAAHDqyfsa1d69e8eePXtizpw5kc1mo1OnTjF27Njal/4rKyvrXEzbqlWr+O53vxsPPfRQ3HbbbdGiRYsYOHBgg7/KCgAADsvkTqJz8Tt27HCNagHIZDLRrl272Lp1q5eKCoB5FxbzLizmXVhKSkqidevWx/Q+/SJTAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJBU35qClS5fGwoULI5vNRkVFRYwaNSq6du36fx63atWqmDx5cnz0ox+N22+/vTEPDQBAgcj7jOozzzwTM2bMiOHDh8fEiROjoqIiJkyYELt3737X47Zv3x6/+MUv4kMf+lCjFwsAQOHIO1QXLVoUAwYMiP79+0eHDh1i9OjRUVpaGitXrjziMTU1NXHffffFtddeG23atHlPCwYAoDDkFarV1dWxcePG6Nmz5/+/g6Ki6NmzZ6xbt+6Ix82dOzfKysrisssua/xKAQAoKHldo7pnz56oqamJ8vLyOtvLy8tjy5YtDR7z8ssvx4oVK+Kee+456sepqqqKqqqq2tuZTCaaNWsWmUwmMplMPkvmJHR4xmZdGMy7sJh3YTHvwnI85tyoN1MdrX379sV9990XN998c5SVlR31cfPmzYu5c+fW3u7cuXNMnDgxWrVqdTyWSaLatm3b1EvgBDLvwmLehcW8aay8QrWsrCyKiooim83W2Z7NZuudZY2IePPNN2PHjh0xceLE2m25XC4iIkaMGBGTJk1q8Jt36NChMXjw4Nrbhwu9srKyzplWTk2ZTCbatm0b27Ztq/1+4dRl3oXFvAuLeReWkpKSY35SMa9QLS4uji5dusSaNWvikksuiYi33yi1Zs2auPLKK+vtf/bZZ8cPf/jDOtseffTR2L9/f9x0001HfDIlJSVRUlJSb3sul/ONXkDMu7CYd2Ex78Ji3oXheMw475f+Bw8eHPfff3906dIlunbtGkuWLIkDBw5Ev379IiJiypQp0aJFixg5cmSUlpZGx44d6xx/5plnRkTU2w4AAP9b3qHau3fv2LNnT8yZMyey2Wx06tQpxo4dW/vSf2VlpYumAQB4zzK5k+hc/I4dO1yjWgAymUy0a9cutm7d6qWiAmDehcW8C4t5F5aSkpJo3br1Mb3PvH/hPwAAnAhCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIElCFQCAJAlVAACSJFQBAEiSUAUAIEnFjTlo6dKlsXDhwshms1FRURGjRo2Krl27Nrjvk08+Gb/61a/itddei4iILl26xHXXXXfE/QEAIKIRZ1SfeeaZmDFjRgwfPjwmTpwYFRUVMWHChNi9e3eD+69duzb69OkTd955Z4wfPz5atmwZ48ePj507d77nxQMAcOrKO1QXLVoUAwYMiP79+0eHDh1i9OjRUVpaGitXrmxw/1tuuSWuuOKK6NSpU7Rv3z7GjBkTuVwuXnzxxfe8eAAATl15vfRfXV0dGzdujCFDhtRuKyoqip49e8a6deuO6j4OHDgQ1dXV8f73v/+I+1RVVUVVVVXt7UwmE82aNYtMJhOZTCafJXMSOjxjsy4M5l1YzLuwmHdhOR5zzitU9+zZEzU1NVFeXl5ne3l5eWzZsuWo7uORRx6JFi1aRM+ePY+4z7x582Lu3Lm1tzt37hwTJ06MVq1a5bNcTnJt27Zt6iVwApl3YTHvwmLeNFaj3kzVWPPnz49Vq1bFXXfdFaWlpUfcb+jQoTF48ODa24cLvbKyss6ZVk5NmUwm2rZtG9u2bYtcLtfUy+E4M+/CYt6FxbwLS0lJyTE/qZhXqJaVlUVRUVFks9k627PZbL2zrO/02GOPxfz582PcuHFRUVHxrvuWlJRESUlJve25XM43egEx78Ji3oXFvAuLeReG4zHjvN5MVVxcHF26dIk1a9bUbqupqYk1a9ZE9+7dj3jcggUL4pe//GWMHTs2zj333MavFgCAgpH3u/4HDx4cy5cvj6eeeipef/31mD59ehw4cCD69esXERFTpkyJmTNn1u4/f/78mD17dnz1q1+NNm3aRDabjWw2G/v37z9mTwIAgFNP3teo9u7dO/bs2RNz5syJbDYbnTp1irFjx9a+9F9ZWVnnXV/Lli2L6urq+NGPflTnfoYPHx7XXnvte1s9AACnrEzuJLpoZMeOHd5MVQAymUy0a9cutm7d6pqmAmDehcW8C4t5F5aSkpJo3br1Mb3PvF/6BwCAE0GoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkqbsxBS5cujYULF0Y2m42KiooYNWpUdO3a9Yj7r169OmbPnh07duyItm3bxvXXXx8f+chHGr1oAABOfXmfUX3mmWdixowZMXz48Jg4cWJUVFTEhAkTYvfu3Q3u/8orr8TkyZPjsssui4kTJ8bHPvaxuPfee+Mvf/nLe148AACnrrxDddGiRTFgwIDo379/dOjQIUaPHh2lpaWxcuXKBvdfsmRJXHTRRfG5z30uOnToECNGjIguXbrE0qVL3/PiAQA4deX10n91dXVs3LgxhgwZUrutqKgoevbsGevWrWvwmHXr1sXgwYPrbLvwwgvj2WefPeLjVFVVRVVVVe3tTCYTzZo1i+LiRl2pwEkmk8lERERJSUnkcrkmXg3Hm3kXFvMuLOZdWI5Hp+V1j3v27ImampooLy+vs728vDy2bNnS4DHZbDaaN29eZ1vz5s0jm80e8XHmzZsXc+fOrb3dp0+fuPXWW+Oss87KZ7mc5Fq1atXUS+AEMu/CYt6FxbwLS1VVVZSUlByT+0ryXf9Dhw6NBx98sPbPF77whZg8eXLs27evqZfGCbBv3774l3/5F/MuEOZdWMy7sJh3Ydm3b19Mnjy5zqvi71VeoVpWVhZFRUX1zoZms9l6Z1kPKy8vr/dGq927dx9x/4i3XyI444wzav80a9YsVq1a5WWDApHL5WLTpk3mXSDMu7CYd2Ex78KSy+Vi1apVx/Q+8wrV4uLi6NKlS6xZs6Z2W01NTaxZsya6d+/e4DHdu3ePF198sc62F154Ibp169aI5QIAUCjyful/8ODBsXz58njqqafi9ddfj+nTp8eBAweiX79+ERExZcqUmDlzZu3+V111VTz//POxcOHCeOONN2LOnDnx6quvxpVXXnnMngQAAKeevN+e1bt379izZ0/MmTMnstlsdOrUKcaOHVv7Un5lZWXtu/wiInr06BG33HJLPProozFr1qxo165d3HbbbdGxY8ejfsySkpIYPnz4Mbswl7SZd2Ex78Ji3oXFvAvL8Zh3JufCEQAAEpTku/4BAECoAgCQJKEKAECShCoAAEk69h/K2khLly6NhQsXRjabjYqKihg1alR07dr1iPuvXr06Zs+eHTt27Ii2bdvG9ddfHx/5yEdO4Ip5L/KZ95NPPhm/+tWv4rXXXouIiC5dusR11133rt8fpCXff9+HrVq1KiZPnhwf/ehH4/bbbz8BK+VYyHfef/vb32LWrFnxu9/9Lvbu3RutW7eOG2+80c/0k0S+8168eHE88cQTUVlZGWVlZXHppZfGyJEjo7S09ASumnytXbs2Hnvssdi0aVPs2rUrvv3tb8cll1zyrse89NJLMWPGjHjttdeiZcuWMWzYsNpfZ3q0kjij+swzz8SMGTNi+PDhMXHixKioqIgJEybU+0Srw1555ZWYPHlyXHbZZTFx4sT42Mc+Fvfee2/85S9/OcErpzHynffatWujT58+ceedd8b48eOjZcuWMX78+Ni5c+cJXjmNke+8D9u+fXv84he/iA996EMnaKUcC/nOu7q6OsaPHx87duyIb33rWzFp0qS4+eabo0WLFid45TRGvvN++umnY+bMmXHNNdfEj3/84xgzZkysXr06Zs2adYJXTr4OHDgQnTp1ii996UtHtf/27dvj7rvvjg9/+MNxzz33xKBBg2LatGnxpz/9Ka/HTSJUFy1aFAMGDIj+/ftHhw4dYvTo0VFaWhorV65scP8lS5bERRddFJ/73OeiQ4cOMWLEiOjSpUssXbr0BK+cxsh33rfccktcccUV0alTp2jfvn2MGTMmcrlcvU88I035zjvi7U+8u+++++Laa6+NNm3anMDV8l7lO+8VK1bE3r1747bbbovzzjsv2rRpE+eff3506tTpxC6cRsl33q+88kr06NEj+vbtG23atIkLL7ww+vTpExs2bDjBKydfF198cYwYMeL/PIt62BNPPBFt2rSJG264ITp06BBXXnllfPzjH4/Fixfn9bhNHqrV1dWxcePG6NmzZ+22oqKi6NmzZ6xbt67BY9atW1dn/4iICy+8MNavX39c18p715h5v9OBAweiuro63v/+9x+vZXKMNHbec+fOjbKysrjssstOxDI5Rhoz7z/84Q/RrVu3+PnPfx6jR4+Of/7nf47/+q//ipqamhO1bBqpMfPu0aNHbNy4sTZM33zzzfjjH/8YF1988QlZMyfO+vXrG2y1o/1v/WFNfo3qnj17oqampvaTrQ4rLy+PLVu2NHhMNpuN5s2b19nWvHnzyGazx2mVHCuNmfc7PfLII9GiRYt6/wBIT2Pm/fLLL8eKFSvinnvuOQEr5FhqzLzffPPN2LFjR/Tt2ze+853vxLZt22L69Olx6NChuOaaa07Aqmmsxsy7b9++sWfPnhg3blxERBw6dCg+85nPxNVXX328l8sJdqRW27dvXxw8ePCor0lu8lCFfMyfPz9WrVoVd911lwvvT0H79u2L++67L26++eYoKytr6uVwAuRyuSgrK4ubb745ioqKokuXLrFz58547LHHhOop6KWXXop58+bFl7/85ejWrVts27YtHnjggZg7d24MHz68qZdHgpo8VMvKyqKoqKje2dBsNlvv/9IOKy8vr3eh9u7du4+4P+lozLwPe+yxx2L+/Pkxbty4qKioOH6L5JjJd96Hz65NnDixdtvhT3keMWJETJo0Kdq2bXs8l8x70Nif58XFxVFU9P+vRGvfvn1ks9morq6O4uIm/88UR9CYec+ePTs++clPxoABAyIiomPHjrF///746U9/GldffXWd7wNObkdqtWbNmuV1oqnJvyOKi4ujS5cusWbNmtptNTU1sWbNmujevXuDx3Tv3r3eG2leeOGF6Nat23FdK+9dY+YdEbFgwYL45S9/GWPHjo1zzz33RCyVYyDfeZ999tnxwx/+MO65557aP7169ap912irVq1O5PLJU2P+fffo0SO2bdtW55rUrVu3xllnnSVSE9eYeR84cCAymUydbeL01NStW7cGW+3d/lvfkCS+OwYPHhzLly+Pp556Kl5//fWYPn16HDhwoPZ3bU2ZMiVmzpxZu/9VV10Vzz//fCxcuDDeeOONmDNnTrz66qtx5ZVXNtEzIB/5znv+/Pkxe/bs+OpXvxpt2rSJbDYb2Ww29u/f30TPgHzkM+/S0tLo2LFjnT9nnnlmnH766dGxY0fhchLI99/35ZdfHnv37o0HH3wwtmzZEs8991zMmzcvrrjiiiZ6BuQj33n36tUrli1bFqtWrYrt27fHCy+8ELNnz45evXoJ1sTt378/Nm/eHJs3b46It3/91ObNm6OysjIiImbOnBlTpkyp3f/yyy+P7du3x8MPPxxvvPFGPP7447F69eoYNGhQXo+bxE/93r17x549e2LOnDmRzWajU6dOMXbs2NqXDiorK+v8H1iPHj3illtuiUcffTRmzZoV7dq1i9tuuy06duzYRM+AfOQ772XLlkV1dXX86Ec/qnM/w4cPj2uvvfZELp1GyHfenNzynXerVq3iu9/9bjz00ENx2223RYsWLWLgwIExZMiQpnkC5CXfeQ8bNiwymUw8+uijsXPnzigrK4tevXrFdddd10TPgKP16quvxve///3a2zNmzIiIiE996lPx9a9/PXbt2lUbrRERbdq0iTvuuCMeeuihWLJkSbRs2TLGjBkTF110UV6Pm8kdvgAMAAAS4jw7AABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkv4fHc4GrO0dc3cAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(results.history[\"loss\"], label=\"loss\", color=sns.xkcd_rgb['greenish teal'])\n",
    "plt.plot(results.history[\"val_loss\"], label=\"val_loss\", color=sns.xkcd_rgb['amber'])\n",
    "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.legend()\n",
    "# plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
