{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "103201b0",
   "metadata": {},
   "source": [
    "# Machine Learning for Neuroimaging\n",
    "\n",
    "### Python/ML basics programming - 10.5.2023\n",
    "\n",
    "### Outline of this tutorial:\n",
    "1. Create Jupyter Notebook\n",
    "2. Load useful packages\n",
    "3. Numpy\n",
    "4. Lists\n",
    "5. Dictionaries\n",
    "6. Dataframes\n",
    "7. Load dataset\n",
    "8. Data outlier exploration\n",
    "9. Fill out missing values\n",
    "10. Visualize ages of cohorts\n",
    "11. Visualize frequency across sexes\n",
    "12. Classify subjects using random forest\n",
    "13. Classify subjects using KNN\n",
    "14. Classify subjects using multi-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcec368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # matrices and mathematics\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hello Jupyter!')\n",
    "\n",
    "# Simple numerical operations\n",
    "\n",
    "a = 12\n",
    "b = 2\n",
    "\n",
    "print(a + b)\n",
    "print(a**b)\n",
    "print(a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eaedf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with lists\n",
    "\n",
    "# Lists are a versatile way of organizing your data in Python. \n",
    "xList = [1, 2, 3, 4]\n",
    "print(xList)\n",
    "\n",
    "# Concatenation\n",
    "x = [1, 2, 3, 4];\n",
    "y = [5, 6, 7, 8];\n",
    "\n",
    "print(x + y)\n",
    "\n",
    "# Sum a list of numbers\n",
    "print(np.sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b030922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries are useful for storing and retrieving data as key-value pairs. \n",
    "# Here is a short dictionary of some example subjects. \n",
    "# The keys are subject names, and the values are the corresponding Age.\n",
    "\n",
    "mw = {'Magda': 30, 'David': 18, 'George':32, 'Jenny': 44}\n",
    "print(mw)\n",
    "\n",
    "# We can add a new value to an existing dictionary.\n",
    "mw['Lisa'] = 50\n",
    "print(mw)\n",
    "\n",
    "# We can also retrieve a value from a dictionary.\n",
    "print(mw['Lisa'])\n",
    "\n",
    "# We can also delete a value from a dictionary\n",
    "del mw['David']\n",
    "print(mw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973175e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A for loop is a useful means of interating over all key-value pairs of a dictionary.\n",
    "\n",
    "for species in mw.keys():\n",
    "    print(f\"The ages of {species} is {mw[species]:.2f}\")\n",
    "\n",
    "# Dictionaries can be quickly sorted by key\n",
    "for species in sorted(mw):\n",
    "    print(f\"{species} {mw[species]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d24e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From dictionaries to dataframes --> Great for data analysis and visualization\n",
    "df_mw = pd.DataFrame.from_dict(mw, orient='index', columns=['Age'])\n",
    "print(df_mw)\n",
    "print('-------------------')\n",
    "\n",
    "# To view data in case you have a large dataset you can use the head() function\n",
    "print(df_mw.head(3)) # first 3 rows\n",
    "print('-------------------')\n",
    "\n",
    "# describe() shows a quick statistic summary of your data\n",
    "print(df_mw.describe())\n",
    "print('-------------------')\n",
    "\n",
    "# Transposing your data\n",
    "print(df_mw.T)\n",
    "print('-------------------')\n",
    "\n",
    "# Get a specific column\n",
    "print(df_mw['Age'])\n",
    "print('-------------------')\n",
    "# Get a specific row\n",
    "print(df_mw.loc['Magda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column\n",
    "df_mw['Year Of Birth'] = 2023 - df_mw['Age']\n",
    "print(df_mw)\n",
    "print('-------------------')\n",
    "\n",
    "# Select multiple columns\n",
    "df_mw_select = df_mw[['Age', 'Year Of Birth']]\n",
    "print(df_mw_select)\n",
    "print('-------------------')\n",
    "\n",
    "# Select values with a condition\n",
    "df_mw_select = df_mw_select[df_mw_select['Age'] > 30]\n",
    "print(df_mw_select)\n",
    "print('-------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20154f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt # Plots\n",
    "import seaborn as sns # Plots\n",
    "from sklearn.ensemble import RandomForestClassifier # Random forest classifier\n",
    "from sklearn.datasets import make_classification # Utils for classification\n",
    "from sklearn.neural_network import MLPClassifier # Multi-layer perceptron\n",
    "from sklearn.model_selection import train_test_split # Split data to train and test set\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score # Accuracy metrics for classification\n",
    "from sklearn import metrics # Metrics for classification (we will use Area Under the Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0981dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the size/resolution of plots\n",
    "%matplotlib inline\n",
    "a4_dims = (9.7, 3.27)\n",
    "plt.rcParams['figure.dpi'] = 500\n",
    "plt.rcParams['savefig.dpi'] = 500\n",
    "plt.rcParams[\"figure.autolayout\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c9a469",
   "metadata": {},
   "source": [
    "## Autism Screening on Adults\n",
    "\n",
    "Autism, or autism spectrum disorder (ASD), refers to a broad range of conditions characterized by challenges with social skills, repetitive behaviors, speech and nonverbal communication.\n",
    "\n",
    "This dataset is composed of survey results for more than 700 subjects who filled an app form containing a quick referral guide for adults with suspected autism who do not have a learning disability. Their labels (Control vs. ASD) portray whether the subjects received a diagnosis of autism, based on the [AQ-10 Autism Spectrum Quotient (AQ) NHS Questionnaire](https://docs.autismresearchcentre.com/tests/AQ10.pdf) and were refered to a specialist for further diagnostic assessment.\n",
    "\n",
    "[Download dataset from Kaggle](https://www.kaggle.com/datasets/andrewmvd/autism-screening-on-adults?resource=download)\n",
    "\n",
    "[Download dataset from Google Drive](https://drive.google.com/file/d/1eaiAcaHQuMEpP5xTmGg3AI8DaZt09er_/view?usp=sharing)\n",
    "\n",
    "[Dataset Website](https://archive.ics.uci.edu/ml/datasets/Autism+Screening+Adult#)\n",
    "\n",
    "- Thabtah, Fadi. \"An accessible and efficient autism screening method for behavioural data and predictive analyses.\" Health informatics journal 25.4 (2019): 1739-1755.\n",
    "\n",
    "- Allison, Carrie, Bonnie Auyeung, and Simon Baron-Cohen. \"Toward brief “red flags” for autism screening: the short autism spectrum quotient and the short quantitative checklist in 1,000 cases and 3,000 controls.\" Journal of the American Academy of Child & Adolescent Psychiatry 51.2 (2012): 202-212.\n",
    "\n",
    "| Feature      | Description |\n",
    "| ----------- | ----------- |\n",
    "| index      | Participant ID       |\n",
    "| AX_Score   | Score based on the Autism Spectrum Quotient (AQ) 10 item screening tool AQ-10        |\n",
    "| age   | Age in years        |\n",
    "| gender   | Participant gender        |\n",
    "| ethnicity   | Ethnicities in text form        |\n",
    "| jaundice   | Whether or not the participant was born with jaundice       |\n",
    "| austim(typo in the original csv) | Whether or not anyone in the immediate family has been diagnosed with autism |\n",
    "| country_of_res | Country of residency |\n",
    "| used_app_before | Whether the participant has used a screening app |\n",
    "| result | Score from the AQ-10 screening tool (sum of positive categories) |\n",
    "| age_desc | Age as categorical variable |\n",
    "| relation | Relation of person who completed the test |\n",
    "| Class/ASD | Participant classification to control vs ASD |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c51ac88",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea75942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv dataset\n",
    "dataframe = pd.read_csv('autism_screening.csv')\n",
    "\n",
    "# Print the first 5 rows of our dataset\n",
    "dataframe.head(5)\n",
    "\n",
    "# Notice the dataframe: What can you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3efeb07",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4019df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for outliers in the data\n",
    "\n",
    "# Describe returns information about the numerical columns of our dataset\n",
    "dataframe.describe()\n",
    "\n",
    "# Max age?\n",
    "# What is the plan of action?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12091d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax1 = sns.boxplot(x=\"Class/ASD\", y=\"age\", data=dataframe, notch=True)\n",
    "ax1.set_ylabel(\"Age - With outlier\", fontsize = 14)\n",
    "ax1.set_xlabel(\"Class/ASD\", fontsize = 14)\n",
    "ax1.set_xticklabels([\"Control\", \"Autism\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371ccf83",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1049003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with outlier from the data\n",
    "outlier_row = dataframe.loc[dataframe['age']==383]\n",
    "dataframe.drop(outlier_row.index, inplace=True)\n",
    "\n",
    "# Describe returns information about the numerical columns of our dataset\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f37140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with Missing Values\n",
    "\n",
    "# Sometimes missing values are marked with ? or NaN or an empty cell\n",
    "dataframe = dataframe.replace({'?':np.NaN})\n",
    "\n",
    "# Check how many values are missing per column\n",
    "missing_values_before = dataframe.isnull().sum()\n",
    "\n",
    "# Show amount of missing values per column\n",
    "pd.DataFrame(missing_values_before, columns=[\"Missing Data\"])\n",
    "\n",
    "# What do you suggest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8047f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out missing age values with mean age - Continuous value\n",
    "dataframe['age'] = dataframe['age'].fillna(np.round(dataframe['age'].mean(), 0))\n",
    "\n",
    "# Replace missing ethnicities and relations with 'Other' as we do not know the actual category\n",
    "dataframe = dataframe.replace({np.NaN:'Other'})\n",
    "\n",
    "missing_values_after = dataframe.isnull().sum()\n",
    "\n",
    "# Visualize the missing values per column after imputation\n",
    "dictionary = {\"Missing Data Before Imputation\": missing_values_before, \"Missing Data After Imputation\": missing_values_after}\n",
    "\n",
    "pd.DataFrame.from_dict(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b684a6",
   "metadata": {},
   "source": [
    "## Age of cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataframes for controls and positive subjects after data pre-processing\n",
    "controls = dataframe[dataframe['Class/ASD']=='NO']\n",
    "autism = dataframe[dataframe['Class/ASD'] == 'YES']\n",
    "\n",
    "plt.figure()\n",
    "ax1 = sns.histplot(x=\"age\", data=dataframe, hue=\"Class/ASD\", element=\"step\")\n",
    "ax1.set_ylabel(\"Number of Subjects\", fontsize = 14)\n",
    "ax1.set_xlabel(\"Age\", fontsize = 14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27dec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax1 = sns.boxplot(x=\"Class/ASD\", y=\"age\", data=dataframe, notch=True)\n",
    "ax1.set_ylabel(\"Age - Without outlier\", fontsize = 14)\n",
    "ax1.set_xlabel(\"Class/ASD\", fontsize = 14)\n",
    "ax1.set_xticklabels([\"Control\", \"Autism\"])\n",
    "\n",
    "# Notice the notches of the boxplot!\n",
    "# Since the notches in the box plot do not overlap, we can conclude, with 95% confidence, \n",
    "# that the true medians do differ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f9337c",
   "metadata": {},
   "source": [
    "## Frequences of sexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c3e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count males/females\n",
    "plt.figure()\n",
    "ax1 = sns.histplot(data=dataframe, x='gender', hue=\"Class/ASD\", shrink=.8, multiple=\"dodge\")\n",
    "ax1.set_ylabel(\"Number of Subjects\", fontsize = 14)\n",
    "ax1.set_xlabel(\"Sex\", fontsize = 14)\n",
    "ax1.set_xticks([0, 1])\n",
    "ax1.set_xticklabels([\"Female\", \"Male\"], fontsize = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1c029b",
   "metadata": {},
   "source": [
    "## Autism Classification \n",
    "\n",
    "Train a model $f$ that given an input $x$ predicts a classification label $y$\n",
    "\n",
    "In this problem $x$ denotes the input features of the questionnaire and $y$ is the subject classification to control and ASD based on their responses\n",
    "\n",
    "Which classifier would you use? Why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80635e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data for classification\n",
    "\n",
    "# The features we want to use to classify Control vs ASD are the responses to the autism questionnaire after the residualization\n",
    "features_for_classification = ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', \n",
    "                               'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score']\n",
    "\n",
    "# Input feature for training\n",
    "X = dataframe[features_for_classification]\n",
    "\n",
    "# Class label\n",
    "Y = dataframe['Class/ASD']\n",
    "\n",
    "# Transform labels from 'YES'/'NO' to One-hot encodings\n",
    "Y = pd.get_dummies(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff0c64b",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8e2fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to train/test sets - we use the same data splits for the different classifiers\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state=3)\n",
    "\n",
    "# For reproducibility we want to set the seed, it's the only fair way to compare classifiers\n",
    "np.random.seed(seed=3)\n",
    "    \n",
    "Y_test = Y_test.values.argmax(axis=1)\n",
    "\n",
    "# Define Random Forest classifier\n",
    "model_1 = RandomForestClassifier(max_depth=3, n_estimators=200, random_state=3)\n",
    "\n",
    "# Fit classifier using the training set and labels\n",
    "model_1.fit(X_train, Y_train)\n",
    "print('Random Forest has been trained!')\n",
    "\n",
    "# Get the predictions of trained model on the test set\n",
    "Y_pred_model_1 = model_1.predict(X_test)\n",
    "Y_pred_model_1 = Y_pred_model_1.argmax(axis=1)\n",
    "\n",
    "# Which metrics do you think we can use to evaluate our predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f45867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Evaluation\n",
    "\n",
    "# Area Under the curve\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test, Y_pred_model_1, pos_label=1)\n",
    "auc_model_1 = metrics.auc(fpr, tpr)\n",
    "print(\"Area under the curve: {:.3f}\".format(auc_model_1))\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(Y_test, Y_pred_model_1)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "b_accuracy = balanced_accuracy_score(Y_test, Y_pred_model_1)\n",
    "print(\"Balanced Accuracy: {:.2f}%\".format(b_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c499aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance with Random Forest\n",
    "\n",
    "# Get feature names and importances from trained model\n",
    "feature_names = X.columns\n",
    "feature_imp = pd.Series(model_1.feature_importances_,index=feature_names.values).sort_values(ascending=False)\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(x=feature_imp[0:10], y=feature_imp.index[0:10])\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Feature Names')\n",
    "plt.title(\"Visualizing Random Forest Important Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de8426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Classifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, Y_train)\n",
    "\n",
    "print('KNN Classifier has been trained!')\n",
    "\n",
    "# Get the predictions of trained model on the test set\n",
    "Y_pred_neigh = neigh.predict(X_test)\n",
    "Y_pred_neigh = Y_pred_neigh.argmax(axis=1)\n",
    "\n",
    "# KNN Evaluation\n",
    "\n",
    "# Area Under the curve\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test, Y_pred_neigh, pos_label=1)\n",
    "auc_neigh = metrics.auc(fpr, tpr)\n",
    "print(\"Area under the curve: {:.3f}\".format(auc_neigh))\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(Y_test, Y_pred_neigh)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "b_accuracy = balanced_accuracy_score(Y_test, Y_pred_neigh)\n",
    "print(\"Balanced Accuracy: {:.2f}%\".format(b_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb665a",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f259df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Layer Perceptron Classifier\n",
    "\n",
    "# hidden_layer_sizes=(16,8) --> two hidden layers, one with 16 neuros and one with 8. In total 4 layers\n",
    "# Input (10 features) + hidden layer 1 (16) + hidden layer 2 (8) + Output layer (2 outputs for binary classification)\n",
    "model_2 = MLPClassifier(random_state=3, max_iter=800,verbose=True, hidden_layer_sizes=(16,8))\n",
    "model_2.fit(X_train, Y_train)\n",
    "\n",
    "print('Multi-layer perceptron has been trained!')\n",
    "\n",
    "Y_pred_model_2 = model_2.predict(X_test)\n",
    "Y_pred_model_2 = Y_pred_model_2.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921eec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Evaluation\n",
    "\n",
    "# Calculate area under the curve\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test, Y_pred_model_2, pos_label=1)\n",
    "auc_model_2 = metrics.auc(fpr, tpr)\n",
    "print(\"Area under the curve: {:.3f}\".format(auc_model_2))\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(Y_test, Y_pred_model_2)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "b_accuracy = balanced_accuracy_score(Y_test, Y_pred_model_2)\n",
    "print(\"Balanced Accuracy: {:.2f}%\".format(b_accuracy * 100))\n",
    "\n",
    "# How can we compare the two classifiers?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
